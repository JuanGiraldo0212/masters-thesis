\startchapter{Run-Time Evolution Reference Architecture}
\label{chapter:reference-architecture}

\minitoc

This chapter addresses self-regulation as introduced in Chapter~\ref{chapter:contribution-overview}. We focus on realizing self-evolution from a control theory perspective (\cf{Section~\ref{subsect:overview--self-management}}). Although the challenges discussed in this chapter manifest in various types of systems, including cloud software applications, they are best exemplified in the context of large-scale \gls{cps}. Given their complexity and, more importantly, the natural properties of real-world entities and the implications of run-time adaptations on them, \gls{cps} pose quality considerations critical for their operational success. Therefore, we base our contribution on \gls{cps}.

The proliferation of \gls{scps} is increasingly blurring the boundary between physical and digital properties of real-world entities. \gls{scps} are engineered systems with augmented reasoning, learning, control, and autonomic capabilities to manage entities and processes in deeply intertwined virtual and physical environments~\cite{tavcar-2019-review}. % The confluence of these systems and technological advances in Internet of Things, Cloud Computing, Big Data and Artificial Intelligence (AI) is transforming multiple application domains radically~\cite{huang-2017-building}. In particular, \gls{scps} are pushing for growth and innovation in complex and ever-evolving domains, such as smart cities and manufacturing, personalized healthcare, as well as intelligent transportation.
As these systems continue permeating the whole human activity spectrum, their operational contexts and interactions with users and surroundings become increasingly hard to anticipate fully~\cite{zeng-2016-one,zhao-2018-systems,bennaceur-2019-modelling}. \glspl{scps}'s inherently dynamic nature demands abilities to accommodate to the physical environment's run-time complexity and uncertainty in the short and long term~\cite{muller-2017-rise,tavcar-2019-review}. This refers to the ability to self-adapt and self-evolve to deal with unpredictable change~\cite{bennaceur-2019-modelling}. However, the potential impact of such self-driven actions on uncertain environments calls for their evaluation prior to materialization. Consequently, the design of \gls{scps} must strive for dependable autonomic capabilities, while ensuring operational resiliency.

To provide guarantees about potential adaptations and evolution actions, \gls{scps} require robust and accurate representations of controlled physical entities and their interactions with the environment. However, the intrinsic highly dynamic nature of physical entities challenges \glspl{scps}' competence to mirror and predict significant characteristics effectively throughout prolonged operation. Inevitably, physical entities associated with \gls{scps} are subject to evolutionary and emergent behavior~\cite{holland-2007-taxonomy} from their interactions with their environment, resulting in transformations (\ie{evolution}) of the dynamics of the entities themselves. Therefore, \gls{scps} designers ought to incorporate mechanisms to manage the dynamicity of associated entities and processes, with at least a minimum of operational guarantees.

We envision a continuous engineering cycle where adaptation and evolution work cooperatively to achieve the system goals. In this engineering cycle, continuous evolution plays both a reactive and proactive role explicitly. Its main purpose is to improve the reference models used for controlling the system's operation, thus, ultimately contributing to the managed system's long-term evolution. Therefore, in this chapter, we present our contribution to run-time evolution conceived as a reference architecture for guiding the design of dependable and resilient \gls{cps}. The proposed architecture realizes our envisioned engineering cycle as follows. First, it uses evolutionary optimization and online experimentation, building on the premises presented in Chapter~\ref{chapter:architectural-framework}, to find suitable models to guide the adaptation of the managed system. Second, it uses online experimentation, supported by parameter optimization, to gather evidence of statistically significant improvements over the system's baseline design, thus generating knowledge of possible configuration states and their respective performances. Lastly, our reference architecture accommodates self-evolution for reflecting persistent changes in the physical environment as well as improving the use of resources. Self-adaptation is used to ensure that the managed system operates within acceptable and viable boundaries. Together, these characteristics contribute to achieving dependability and ensuring resiliency for \gls{scps} at run-time.

Dependability and resiliency of \gls{scps} are commonly approached from a cyber-security standpoint. However, an aspect often overlooked is the natural evolution of physical entities external to the system that affect its day-to-day operation. Thus, changes on these entities eventually render adaptation mechanisms irrelevant. Our contribution addresses dependability and resiliency through the design of run-time evolution mechanisms that deal with uncertain operation conditions.

The remainder of this chapter is structured as follows. First, Section~\ref{sect:reference-architecture--overview-of-architecture-in-solution-strategy} contextualizes our reference architecture into the overall solution strategy presented in this dissertation.  Second, Section~\ref{sect:reference-architecture--architecture-overview} introduces our reference architecture for designing \gls{scps} enabled for dependable and resilient run-time evolution.

\begin{InfoBox}[Correspondences in This Chapter]
	\emph{Addressed Challenge(s)}: \textsc{Ch}6---Autonomic managers are required to keep their internal models relevant, aiming to reduce the need for additional maintenance; 
	\emph{Question(s)}: \textsc{Q}7---How can autonomic managers help reduce maintenance work stemming from emerging behavior? 
	\emph{Goal(s)}: \textsc{G}4---Define required design elements to expedite run- time changes when facing emerging behavior; 
	\emph{Contribution(s)}: \textsc{C}3---Run-time evolution reference architecture.
\end{InfoBox}

\section{Overview of the Reference Architecture in Our Solution Strategy}
\label{sect:reference-architecture--overview-of-architecture-in-solution-strategy}

Although sometimes used interchangeably among application domains, system adaptation and evolution are worth exploring and analyzing individually in the context of \gls{scps}. On the one hand, system adaptations are usually considered as control changes to correct deviations from anticipated behavior or to achieve operational goals. Largely, system adaptations are reactive and concern short-term changes during sudden periods of manageable uncertainty. On the other hand, system evolution involves protracted changes that are usually discovered through proactive exploration of alternative system structures and behaviors. Evolution actions usually aim to optimize the system's operation, reflect permanent changes in the system's usage patterns or mitigate potential adverse conditions.

In this chapter, we propose the combination of adaptation and evolution as way of handling short-term and long-term changes in the system's environment. Evolution actions are intended to regulate the \glspl{mart} guiding the overall operation, whereas adaptations focus on meeting the control objectives in the short-term.  Section~\ref{subsect:reference-architecture--dependability-and-resiliency} describes the relevance of evolution and adaptation in \gls{cps} in terms of dependable autonomic behavior, as well as resilient system operation. Section~\ref{subsect:reference-architecture--adaptation-and-evolution-as-operational-modes} explains the need for a more relaxed contract between managed and managing systems, leading to self-evolution as a way to regulate and improve the system. Finally, Section~\ref{subsect:reference-architecture--self-regulated-evolution-of-run-time-artifacts} describes how the mechanisms for self-regulation fit into our offline and online reconceptualization.

\subsection{Dependability and Resiliency in Autonomic Cyber-Physical Systems}
\label{subsect:reference-architecture--dependability-and-resiliency}

Increased autonomy in \gls{cps} results in more uncertainty and thereby more risks. First, internal structures and behavioral models of the managing system may become unsuitable: since elements of the managed system evolve over time, at some point adaptation plans could be synthesized based on inaccurate estimations or outdated \glspl{mart}. Consider our \gls{suts} case study, introduced in Chapter~\ref{chapter:contribution-overview}, as an example. User demand (\ie{daily passengers}) and usage patterns (\ie{demand levels for a particular line at specific day times}) may change temporarily and even permanently. Although many of these changes can be anticipated, such as scheduled events in the city, national holidays or construction projects, many others are fortuitous, such as traffic accidents, protests or bad weather conditions. However, even if these changes can be anticipated, there are no guarantees about their effects or progression over time. Second, managing systems can only guarantee their effectiveness over supported context attributes. Therefore, even if the system is under regular operation, adaptation plans can negatively impact the system's operation. This is because there can be confounding factors unknown to the managing system. Third, small changes can have a great impact on complex systems. Predicting the outcome of an adaptation plan using theoretical models can be futile on a complex system. A first reason is that it is virtually impossible to perform an exhaustive exploration of all possible scenarios; a second one is the impossibility of models to capture the complexity of the managed system and its environment reasonably.

One mitigation strategy for these risks is to involve humans in the adaptation planning process. Human operators are knowledgeable on the different parts of the system, being skillful in assessing adaptation alternatives. Nevertheless, involving humans is costly and introduces the constant possibility of errors, therefore justifying the need for engineering reliable \emph{autonomic} managers. Moreover, human expertise may not be enough in the face of complex system dynamics. For these reasons, we consider the aforementioned risks as relevant quality concerns. Thus, we delegate the task of accounting for these concerns as architecturally significant quality attributes to the managing system.

We group the aforementioned concerns into two quality attributes: \emph{dependability} of the autonomic behavior, and \emph{resiliency} of the overall operation. For the first attribute, we consider necessary to have a trustworthy, evidence-based adaptation planning process. We aim to ensure continuity and readiness of service (\ie{reliability and availability, respectively}). For the second attribute, it is important to provide the system with the necessary means to recognize when it is operating outside of the control objectives' viability zones. That way, the managing system can either optimize control parameters, or take preemptive measures to increase the likelihood of goal fulfillment. Additionally, a run-time verification and validation technique might be necessary to reduce the effect of unidentified confounding factors.

\subsection{Adaptation and Evolution as Autonomic Operational Modes}
\label{subsect:reference-architecture--adaptation-and-evolution-as-operational-modes}

In classical control theory, a controller synthesizes control actions from, and instruments them into, a controlled system for achieving its operational goals. The controlled system lacks any notion of adjustment review, acceptance or rejection because, by design, it is unaware of the controller (\eg{a thermostat}). Autonomic managers perform a similar task in the case of software systems, with the difference that they not only control but manage the system's operation~\cite{diao-2005-control}. Examples of such management capabilities are self-healing, self-protection, self-configuration and self-optimization~\cite{kephart-2003-vision}. Although they are conceptually more advanced than classical controllers, their relationship with the managed system is also based on controlling its execution. Both classical controllers and autonomic managers interface with the managed system through sensing and effecting elements only. %, even though some effectors of advanced autonomic managers rely on introspection and intercession capabilities in the managed software system.
In both cases, their objective is to measure and adapt the managed system's behavior.

Short-term and frequent adaptations, typical of classical control systems, are not suitable for all \gls{cps}. Consider our case study as an example. Adjusting the headway design or the operating fleet size in short periods of time (\eg{within a few minutes}) can be unproductive, ineffective and expensive. Moreover, frequent adaptations may lead to instability, especially if the frequency of the changes causes a long settling time (\ie{the time required for an adaptive system to achieve a desired and steady state})~\cite{villegas-2011-framework}. Since the managing system is likely to consider a limited set of context attributes, unforeseen events may destabilize the managed system further (\eg{road blocks caused by protests or traffic accidents}). Moreover, an adaptation plan may include manual tasks, thereby rendering control mechanisms unfit. Oftentimes, humans in the loop must evaluate, or at least review, the adaptation plan to prevent expensive mistakes. Therefore, the managing system must be able to provide evidence for the predicted outcome to instill confidence in the adaptation plan~\cite{baresi-2010-disappearing,andersson-2013-software,tavcar-2019-review}. These situations do not disregard the need for autonomic control, but evidence the need for a more relaxed contract between managing and managed systems.

While classical controllers are focused on short-term and reactive adaptations, quality properties of large-scale \gls{cps} demand management mechanisms for long-term evolution as well. We conceive this duality---short-term adaptation and long-term evolution---as two operational modes of an autonomic manager. On the one hand, the adaptation operational mode retains the control relationship described previously. On the other hand, the evolution operational mode relaxes the frequency and mandatory nature of the adaptations in favor of eventual evolution. That is, the process of regulating and improving the managed system as opposed to controlling its operation. Moreover, such a process shifts the focus from short-term, non-exploratory and prescriptive adaptations to long-term, exploratory and dynamic adaptations.

Beneficial discoveries found through the evolution operational mode eventually manifest in the managed system, thus completing the evolution cycle between managed and managing systems (\ie{managed system $\rightleftarrows$ managing system}). % From left right, changes are contextual and are generally countered by control actions. And from right to left, changes originate from insights derived from historical data, new sensors, long-running simulations, and experiments.
As the managed system evolves naturally in the real world, so do the managing system's internal models (\ie{evolution in the forward direction}). And whenever the managing system synthesizes an improvement, the adaptation operational mode will enforce the necessary changes for its managed system to accept or reject them (\ie{evolution in the reverse direction}). Furthermore, associated causal connections will also trigger updates in the managed system. This evolution cycle enables continuous engineering throughout the entire system life cycle, even at different levels of granularity. From the managed to the managing system, humans in the loop frequently deliver updates. In the opposite direction, the managing system exploits data that is usually unavailable offline to optimize the use of system resources. This includes, for instance, data from the actual system operation. Furthermore, it is the combination of data devised during development, stakeholder knowledge, and run-time data that would allow \gls{cps} reach other---richer---levels of autonomic behavior.

\subsection{Self-Regulated Evolution of Run-Time Artifacts}
\label{subsect:reference-architecture--self-regulated-evolution-of-run-time-artifacts}

The reference architecture we present in this chapter relies on the self-improvement feedback loop we presented in Chapter~\ref{chapter:architectural-framework}. This chapter concentrates on the use of dynamic simulations to try out distinct configuration scenarios as a response to emerging behavior. The purpose of using the self-improvement feedback loop at run-time is to reify long-lasting descriptive and predictive models to guide short-term adaptations. For example, whenever the usage demand pattern changes for a particular system, the managing system's internal demand model must be updated. In this case, the demand model is a reference control input that should remain relevant for correctly controlling the system's operation.

Figure~\ref{fig:reference-architecture--run-time-self-regulation} depicts how self-regulation fits into the time-of-change timeline. Configuration explorations based on historical data are executed at development-time, and then complemented with data collected during the operation of the managed system. Descriptive and predictive models reified during development are updated in response to emergent behavior. We achieve this through adaptive control. More specifically, we realize the two operational modes described in Section~\ref{subsect:reference-architecture--adaptation-and-evolution-as-operational-modes} through architectural components inspired by \gls{miac} and \gls{mrac}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\columnwidth]{fig/reference-architecture/reference-architecture--run-time-self-improvement.pdf}
	\caption{Self-regulation based on adaptive control}
	\label{fig:reference-architecture--run-time-self-regulation}
\end{figure}

% The use of experimentation in this chapter is twofold. First, it allows comparing treatment and control groups through controlled experiments (\cf{Section~\ref{sect:architectural-framework--online-experiment-design}}). Second, it allows validating predicted outcomes by gradually rolling out an adaptation plan while executing a field experiment (\cf{Section~\ref{sect:architectural-framework--online-experiment-design}}).

\section{Architecture Overview}
\label{sect:reference-architecture--architecture-overview}

This section introduces our reference architecture for dependable and resilient \gls{cps}. We follow the \emph{Views and Beyond} documentation approach~\cite{bass-2003-software} to describe the elements of our architecture and their relationships. We chose to depict these elements with decomposition views (\cf{Figures~\ref{fig:reference-architecture--architecture},~\ref{fig:reference-architecture--control-adapter} and~\ref{fig:reference-architecture--experimentation-subsystem}}) and a behavioral view (\cf{Figure~\ref{fig:reference-architecture--model-identification}}), using an informal notation.

\begin{figure}[h]
	\centering
	\includegraphics[width=1\columnwidth]{fig/reference-architecture/reference-architecture--architecture.pdf}
	\caption{The proposed architecture}
	\label{fig:reference-architecture--architecture}
	Labels~\texttt{A} through~\texttt{G} mark the components that provide support for dependable autonomy~$(\encirclecolor[myblack][myblack]{A})$ and resilient operation~$(\encirclecolor[myyellow][myyellow]{A})$. Labels~\encirclecolord{B} and~\encirclecolord{C} support both quality attributes.
\end{figure}

Figure~\ref{fig:reference-architecture--architecture} is split into three main subsystems: a common knowledge layer, which comprises data sets and \glspl{mart}; a managing system, which comprises elements of an autonomic manager; and a managed system, which refers to the \gls{cps}. Information flowing between the managing and managed systems passes through a modeling layer---an interface to managed resources, regardless of whether they are physical, virtual or conceptual (\eg{a bus line}). This component is responsible for both mirroring the managed system's state to its managing system, and also realizing causal connections from \glspl{mart} to the managed system. Effector components connected with our modeling layer translate changes in the models into updates to the managed system. We call this evolution in the reverse direction (\ie{managed system$\,\leftarrow\,$managing system}). Conversely, We call evolution in the forward direction (\ie{managed system$\,\rightarrow\,$managing system}) to collecting, filtering, aggregating and analyzing sensed data to keep the \glspl{mart} up to date with respect to the current managed system's state.

The concerns described in Section~\ref{subsect:reference-architecture--dependability-and-resiliency} manifest themselves in three main subsystems: A multi-controller subsystem, a model identification mechanism (\gls{mim}) with support for multiple model inferrers, and an adjustment mechanism (\gls{am}) supporting multiple parameter estimators (\cf{$\,\encircleblack{D}$,~$\,\encirclecolord{B}$,~and $\,\encircleyellow{F}$, respectively in Fig.~\ref{fig:reference-architecture--architecture}}). The last two form what we call a dimensional control adapter.

Figure~\ref{fig:reference-architecture--control-adapter} shows three possible configurations of a dimensional control adapter. The first configuration considers one modeling dimension captured in a single \gls{mart} (\cf{Figure~\ref{fig:reference-architecture--control-adapter-a}}). Examples of modeling dimensions include user demand, bus arrivals, and topology of lines and stations. The \gls{am} uses the \gls{mart} as a reference input to adjust the controller's parameters, while the \gls{mim} updates it when necessary. In the context of our case study, a \gls{mim} updates a probability distribution function of bus arrivals for a particular bus line and specific bus stop, whereas an \gls{am} uses it for calculating an appropriate headway design. The second configuration considers at least one modeling dimension captured on several \glspl{mart} (\cf{Figure~\ref{fig:reference-architecture--control-adapter-b}}). In this case, an \gls{am} uses them as reference inputs, while several \glspl{mim} update them when necessary. The third configuration also considers at least one modeling dimension captured on several \glspl{mart} (\cf{Figure~\ref{fig:reference-architecture--control-adapter-c}}). In this case, there is a dimensional control adapter for each of them.

\begin{figure}[h]
	\begin{subfigure}{.33\textwidth}
		\centering
		\includegraphics[width=.95\linewidth]{fig/reference-architecture/reference-architecture--control-adapter-a.pdf}
		\caption{One modeling dimension}
		\label{fig:reference-architecture--control-adapter-a}
	\end{subfigure}%
	\begin{subfigure}{.33\textwidth}
		\centering
		\includegraphics[width=.95\linewidth]{fig/reference-architecture/reference-architecture--control-adapter-b.pdf}
		\caption{At least one modeling dimension captured on several models}
		\label{fig:reference-architecture--control-adapter-b}
	\end{subfigure}
	\begin{subfigure}{.33\textwidth}
		\centering
		\includegraphics[width=.95\linewidth]{fig/reference-architecture/reference-architecture--control-adapter-c.pdf}
		\caption{Like (b) but with independent models and adjustment mechanisms}
		\label{fig:reference-architecture--control-adapter-c}
	\end{subfigure}
	\caption{The dimensional control adapter}
	\label{fig:reference-architecture--control-adapter}
\end{figure}

Sections~\ref{subsect:reference-architecture--achieving-dependability} and~\ref{subsect:reference-architecture--achieving-resiliency} further describe the elements of our architecture under the light of quality attributes dependability and resiliency. And Section~\ref{subsect:reference-architecture--knowledge-layer} details relevant aspects of the knowledge layer we propose.


\subsection{Achieving a Dependable Autonomy}
\label{subsect:reference-architecture--achieving-dependability}

Our architecture addresses dependable autonomy in multiple ways (\cf{labels~$\,\encircleblack{A}\,$ through~$\,\encirclecolor{D}$ in Figure~\ref{fig:reference-architecture--architecture}}) as follows.

\subsubsection[Error mitigation through multi-model identification]{Error mitigation through multi-model identification ($\encircleblack{A}$)}

Model identification, inference or estimation are useful techniques to obtain a model given an initial data set of historical data. Nevertheless, while the generated data is useful, it is not always accurate. By implementing several techniques, the \gls{mim} can either select the model with the smallest estimated error, or combine them as shown with the multi-controller approach (\cf{Section~\ref{subsect:background--control-theory}}). Examples of model inference are function approximation using interpolation or symbolic regression. Regarding our \gls{suts} case study, by using a queuing network model of a \gls{brt} system, a \gls{mim} could simulate many headway design values, thus obtaining their corresponding excess waiting times. Then, it could use symbolic regression to find a function using the known data points.

\subsubsection[Reliable models through model inference]{Reliable models through model inference ($\encircleblack{B}$)}

The \gls{mim} realizes the evolution operational mode. The \texttt{mode} \texttt{supervisor} component monitors the control objectives and their viability zones, looking for a drift between reference and measured values. Whenever a variable of interest goes from an inaccurate state (\ie{mild drift from the expected value}) to an unknown state (\ie{the model cannot reliably predict future values}), the \gls{mim} is activated to synthesize an improved model. By evolving the \glspl{mart}, the \gls{mim} keeps the control parameters relevant, thus contributing to the dependability of the autonomic manager.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\columnwidth]{fig/reference-architecture/reference-architecture--viability-zone.pdf}
	\caption{Viability zone for a particular variable of interest}
	\label{fig:reference-architecture--viability-zone}
\end{figure}

Figure~\ref{fig:reference-architecture--viability-zone} illustrates the relationship between referenced and measured values with respect to the system state. The chart depicts the progression of a variable of interest, such as the user demand after a peak hour for a particular bus line and station. Right before the second data consolidation, the mode supervisor identifies a mild drift between the expected and actual values. When there is enough data available, the mode supervisor predicts further drift based on historical data and domain knowledge. Whenever the drift between these values is unacceptably large, the number of control actions increases (\ie{adaptations}). For example, when the value is expected to be strictly decreasing but it starts to increase. However, when the measured value enters an unknown state, that is, the reference value is no longer reliable, the mode supervisor switches from the adaptation to the evolution operational mode.

\subsubsection[Evidence collection through experimentation]{Evidence collection through experimentation ($\encircleblack{C}$)}

Evidence-based decision making is an effective way of mitigating the risk of unwanted effects. The \gls{mim} uses online experimentation to design and conduct experiments. This allows the \gls{mim} to test multiple models by varying input parameters of the particular method being used. This is known as hyperparameter optimization, and is used in techniques such as gradient-based and evolutionary optimization. Figure~\ref{fig:reference-architecture--experimentation-subsystem} depicts the experimentation subsystem, and Figure~\ref{fig:reference-architecture--model-identification} illustrates a detailed view of the data flow. A client component requests to the experimentation subsystem to design and conduct an experiment, passing a set of treatment functions and an experimentation goal as parameters. The \texttt{experimentation feedback loop} creates an experiment following the workflow presented in Chapter~\ref{chapter:architectural-framework}. Then, the \texttt{configuration feedback loop} uses the functions to devise different groups (\eg{control and treatment groups}), and deploys them to the \texttt{experiment execution environment} according to the design. The target subjects may reside in various types of environments, including a simulation, a computing platform or the real world. Each deployed artifact is considered to be an independent system instance, therefore it provides sensing and predicting capabilities. The configuration feedback loop measures and aggregates metrics of the variable of interest. The experimentation feedback loop then uses these metrics to conduct statistical tests (\eg{normality and analysis of variance}) and hypothesis testing. Then, it can decide whether the experiment has achieved its goal or needs to be adapted. Once the experiment is terminated, the client receives a list of subject groups sorted by a particular metric of interest, and clustered based on similarity.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.55\columnwidth]{fig/reference-architecture/reference-architecture--experimentation-subsystem.pdf}
	\caption{The experimentation subsystem}
	\label{fig:reference-architecture--experimentation-subsystem}
\end{figure}
	
\subsubsection[Autonomic behavior through adaptive control]{Autonomic behavior through adaptive control ($\encircleblack{D}$)}

The \texttt{multi-controller subsystem} component in Figure~\ref{fig:reference-architecture--architecture} is inspired by multi-model adaptive control. %, introduced in Section~\ref{subsect:background--control-theory}.
Similarly to the \gls{mim}, its main purpose is to minimize the estimated error when adapting the managed system. Since this subsystem is application-specific, we do not provide further details about it in this section.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\columnwidth]{fig/reference-architecture/reference-architecture--model-identification.pdf}
	\caption{Model identification workflow}
	\label{fig:reference-architecture--model-identification}
\end{figure}

Figure~\ref{fig:reference-architecture--model-identification} depicts interactions between the experimentation subsystem and the model identification mechanism. The shadowed area contains components and activities that exclusively belong to the latter. The rest of the figure shows an alternative view of the experimentation subsystem (\cf{Figure~\ref{fig:reference-architecture--experimentation-subsystem}}).

\subsection{Achieving Resilient Operations}
\label{subsect:reference-architecture--achieving-resiliency}

Our architecture ensures resilient operation through multiple techniques (\cf{labels~$\,\encircleyellow{B}$, $\,\encircleyellow{C}$, $\,\encircleyellow{E}$, $\,\encircleyellow{F}$ and~$\,\encircleyellow{G}\,$ in Figure~\ref{fig:reference-architecture--architecture}}) as follows.

\subsubsection[Predictable adaptation through reliable models]{Predictable adaptation through reliable models ($\encircleyellow{B}$)}

Up-to-date models allow the \gls{am} to plan adaptations based on both relevant inputs and criteria, thus increasing its resiliency in the face of uncertainty. On the one hand, the \gls{am} optimizes control parameters based on reference inputs, thereby ensuring that the controller will work within a known scope and will be able to satisfice the control objectives. On the other hand, the multi-controller subsystem adapts the managed system's behavior based on viability zones that reflect changing conditions instead of fixed constraints. Consider the example in Figure~\ref{fig:reference-architecture--viability-zone}. If the corresponding \gls{mart} is updated right after the third data consolidation, the operation could be optimized for the current conditions. In case the control objectives are not met, the managing system would desist of the task and delegate it to human stakeholders. In any case, the system is aware enough to decide which path to take.

\subsubsection[Run-time validation through evidence collection]{Run-time validation through evidence collection ($\encircleyellow{C}$)}
Run-time validation and verification are required  to reduce the likelihood of adverse effects when adapting the managed system. Our architecture considers a form of run-time validation through continuous experimentation. Instead of deploying a complete adaptation plan, the multi-controller subsystem coordinates with the experimentation subsystem to adapt the managed system partly and assess whether it behaves as expected. For example, instead of updating the headway design for all the bus lines in the system, only a representative group of lines (\ie{the treatment group}) is updated. The experimentation subsystem will run statistical tests to confirm that the adaptation plan yields the predicted outcome. The multi-controller subsystem will gradually roll out the adaptation plan over time until it has been completely deployed.

\subsubsection[Error mitigation through parameter estimation]{Error mitigation through parameter estimation ($\encircleyellow{E}$)}
By considering multiple parameter estimators, the \texttt{multi-adjustment mechanism} mitigates various risks: non-convergent optimizations, inaccurate estimations, and erroneous estimations. Similarly to the \gls{mim}, the multi-adjustment mechanism can either select the estimator with the smallest error or combine them (\cf{Section~\ref{subsect:background--control-theory}}). The effect on the overall adaptation process is that the \gls{am} is less likely to fail in estimating a control parameter, thereby making the estimation more resilient to uncertain conditions. Examples of a parameter estimator are Bayesian, gradient-based and evolutionary optimization.

\subsubsection[Goal achievement through hyperparameter optimization]{Goal achievement through hyperparameter optimization ($\encircleyellow{F}$)}
\label{subsubsect:reference-architecture--goal-achievement-through-optimization}
The \gls{am} aims at estimating control parameters based on reference inputs. Its main purpose is to aid in achieving the control objectives. For example, a gradient-based optimization method, such as gradient descent, can minimize the distance between a given setpoint (\ie{the goal, as defined in the control objective}) and a point evaluated in a known function. For example, an excess waiting time of 5 minutes for a particular line and stop would be possible with a headway design of 3 minutes, for a fixed number of buses. In this case, the method found that when the headway design is 3 minutes, the distance between the actual excess waiting time and the setpoint is minimal. Nonetheless, such a headway is of course highly costly, and it would be affordable only at highly peak times of service.

\subsubsection[Assurance through viability zones and control objectives]{Assurance through viability zones and control objectives ($\encircleyellow{G}$)}
Viability zones are usually conceived as zones whose borders define the threshold between the regular operation of a system and when an adaptation is necessary (\eg{\cite{tamura-2013-towards}}). Our reference architecture extends the notion of a viability zone with an additional threshold, illustrated in Figure~\ref{fig:reference-architecture--viability-zone}. This new threshold delimits the managing system's effectiveness scope with respect to a particular variable of interest. Such a scope may be defined in terms of known contextual situations, availability of adaptation strategies, or limitations of the reference models. For example, consider a machine learning model trained on data for which the current value of a variable would be considered an outlier. Predictions produced by such a model for the current value are not reliable. Similarly, if the reference model being used was inferred by function interpolation and new values of the variable are outside the domain of the original data set, the model cannot produce reliable predictions. The new threshold separates the need for (short-term) adaptation and (long-term) evolution. Therefore, our notion of a viability zone, together with the \gls{mim} and \gls{am}, provides run-time assurance even when the controller falls short at certain contextual situations. Consider our \gls{suts} case study as an example. After a peak hour, the reference model may be expecting a strict decline in user demand. If there is a sudden increase in demand, the measured variable crosses a first threshold, thus assigning the system an inaccurate state (\ie{there is a drift between the expected and actual values}). If the demand continues to increase, the variable will eventually cross a second boundary, assigning the system an unknown state (\ie{the reference model is no longer reliable}). In this case, a demand identification mechanism performs the corresponding statistical tests to identify the new probability distribution, ultimately updating the reference model. At this point, the \gls{am} along with the controller will enforce a new operational state, thus returning the system to an expected state.



\subsection{Realizing the Knowledge Layer}
\label{subsect:reference-architecture--knowledge-layer}

Our reference architecture realizes self-evolution from a control theory perspective. This means that \glspl{mart} are inferred at run-time, in response to emerging behavior in the environment. A perspective missing in the chapter so far is the integration of our architecture with our software evolution pipeline and our self-improvement feedback loop. Without this, autonomic managers built according to our architecture would be isolated from other computing environments in the delivery pipeline. We identify two key advantages justifying such an integration. On the one hand, exploring configuration scenarios can be a time consuming activity, depending on the target environment to where configuration alternatives are deployed. If the search space exploration is conducted entirely at run-time, the \gls{mim} may not be cost-effective or adaptations may not be timely. On the other hand, integrating our reference architecture with our evolution pipeline assists autonomic managers in realizing evolution in the reverse direction (\ie{managed system$\,\leftarrow\,$managing system}). That is, optimized operation parameters can be used to update \glspl{mart}, and in turn, trigger persistent updates on the development side---or physical side, for \glspl{cps}.

The use of knowledge is indeed a common aspect between our continuous software evolution pipeline, our self-improvement feedback loop, and the reference architecture we present in this chapter. In Chapter~\ref{chapter:delivery-platform}, managing systems use \glspl{mart} to mirror the managed system's state and synchronize development artifacts. In Chapter~\ref{chapter:architectural-framework}, feedback loops take advantage of causally-connected \glspl{mart} to produce system variants as a way to improve the managed system. And in this chapter, managing systems reify predictive models to regulate control actions. Together, these contributions embody a holistic framework thus far based on change. Despite knowledge playing a relevant role in evolving, improving and regulating the managed system, its use remains scoped to each specific environment. Knowledge plays an equally relevant---and sometimes overlooked---role in orchestrating feedback loops. In fact, it is through both change and knowledge that the offline and online parts of our envisioned evolution process interface (\cf{Figure~\ref{fig:overview--continuous-software-evolution-process}}).

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\columnwidth]{fig/reference-architecture/reference-architecture--knowledge-layer.pdf}
	\caption{Knowledge layer to support stakeholder interactions beyond change}
	\label{fig:reference-architecture--knowledge-layer}
\end{figure}

This section unifies knowledge aspects of our reference architecture through knowledge modeling and reification. We create a separate layer for storing relevant measurements and \glspl{mart}. In terms of the \gls{mapek} model, this means that we separate the knowledge element from the rest---much like cognitive processes in the human brain (\eg{memory and reasoning}). Thus, we create a common knowledge layer, external to the managing system. In general terms, we aim to promote collaboration between humans in the loop and autonomic managers, which we consider offline and online stakeholders, respectively. Figure~\ref{fig:reference-architecture--knowledge-layer} illustrates our vision. Each autonomic manager at the top of the figure concentrates on a specific aspect of the managed system. Both offline and online stakeholders obtain and augment data sets from the knowledge layer, throughout the delivery pipeline. Offline stakeholders can benefit from knowledge produced online, for example, by augmenting their tools with relevant information (\eg{Monitoring- and performance-aware \glspl{ide}~\cite{winter-2019-monitoring,cito-2019-interactive}}). By doing so, they shorten the feedback cycle from development to production on execution issues (\eg{predicting relevant metrics based on changes to the \gls{osp}}). Online stakeholders can benefit from knowledge produced offline, as well as by knowledge produced by other online stakeholders. In the first case, offline stakeholders can clean collected data, identify data relationships and create behavioral models. In the second case, each autonomic manager explores a portion of the evolution space, based on the concerns they address. At the same time, online stakeholders can focus on a single task, and rely on others to perform associated tasks. For example, an autonomic manager focused on operations planning can update the managed system at run-time, while another one focused on online evolution handles corresponding persistent updates. This integration is based on causal relationships among the \glspl{mart} rather than dependencies among the autonomic managers.% In fact, new knowledge is derived from a \gls{mart} hierarchy, which would be technically more difficult to achieve with an equivalent control hierarchy---from a design and an evolution perspective.

The rest of this section is organized as follows. Section~\ref{subsect:reference-architecture--implicit-and-explicit-knowledge-processing} details how the common knowledge layer fits into the delivery pipeline. Section~\ref{subsect:reference-architecture--online-knowledge-synthesis} concentrates on the continuous engineering cycle we realize in our reference architecture for synthesizing predictive knowledge online.


\subsubsection{Implicit and Explicit Knowledge Processing}
\label{subsect:reference-architecture--implicit-and-explicit-knowledge-processing}

We conceive the knowledge layer as a data store and processing infrastructure for \glspl{mart}. It spans throughout the delivery pipeline, starting from the local development environment and expanding to production. Along the pipeline, offline and online stakeholders get data and \glspl{mart} from the knowledge layer to augment their tools and own datasets. Moreover, since each stakeholder is concerned about distinct requirements, they will feed back valuable knowledge that can later complement another stakeholder's work. For example, an autonomic manager focused on achieving quality of experience goals will monitor passenger arrival times and associated metrics. This information is tremendously useful for a planning agent working from the operations control center. Similarly, an autonomic manager focused on operations planning updates bus schedules according to changes in the \gls{osp}. Changes to these data are input to an autonomic manager focused on predictive bus maintenance, which takes advantage of the updates to book necessary revisions without impacting overall system performance.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.95\columnwidth]{fig/reference-architecture/reference-architecture--implicit-and-explicit-knowledge-processing.pdf}
	\caption{Implicit and explicit knowledge processing}
	\label{fig:reference-architecture--implicit-and-explicit-knowledge-processing}
\end{figure}

Figure~\ref{fig:reference-architecture--implicit-and-explicit-knowledge-processing} depicts the knowledge layer in the context of the delivery pipeline. Although we do not impose an implementation strategy, it is important to note that this layer is not necessarily a database management system accessible from all environments. Although this is one possibility, the knowledge layer can be conceptually anything that transports knowledge from one environment to others following standard methods and formats. The pipeline-wide access can be implemented based on practices from database administration or machine learning, such as database migrations and data versioning.

Conceptually, we split knowledge processing activities into implicit and explicit, from the autonomic managers' perspective. At run-time, all activities conducted to recall or update knowledge are considered as foreground knowledge processing. Conversely, similar activities conducted in any other environment are considered as background knowledge processing. We do this classification to highlight the relevance of choosing the right environment for each activity, always considering that each environment has its own limitations. For example, exploration time is limited at run-time; At development-time, where this is not an issue, execution conditions do not reflect the actual user demand. Moreover, this classification may motivate the creation of new environments. Consider, for example, temporary environments to conduct time-consuming and compute-intensive knowledge processing activities.

We now describe each of the processing activities present in Figure~\ref{fig:reference-architecture--implicit-and-explicit-knowledge-processing}.

\begin{description}[style=unboxed,leftmargin=0cm,font=\bfseries\normalsize]
	\item[Knowledge Maintenance\autodot] Offline stakeholders maintain data sets and \glspl{mart} in their local development environment. Data science engineers can clean up existing data by removing abnormal behavior captured at run-time, or tag it accordingly to prevent skewing analytical models. Moreover, they can augment existing data with special and edge cases to consider unlikely but relevant regions of the search space. A product manager can recall collected metrics and combine them with source code elements to prioritize support tickets based on occurrence or relevance. Moreover, this information can be used to create dynamic reports and make decisions with up to date information. An operations planner can obtain monitoring data from a transportation system to analyze how social and economic factors affect usage patterns to make decisions based on the target population. For example, late-shift workers are more likely to take the bus in the evening, late-night and early-morning in specific parts of the city. In a second example, software developers and roles alike can augment their tools with production information to shorten the feedback cycle for their local changes to the managed system (\eg{Production performance feedback in the \gls{ide}~\cite{cito-2019-interactive}}). The main purpose of the knowledge layer is to support data-driven decisions on the development and planning side. Moreover, since autonomic managers access the same data sets and \glspl{mart}, it promotes improving online decisions over time, as well as increasing systems' autonomy.

	\item[Measurement\autodot] Measuring metrics about the system's operation is critical to understand how changes in the environment affect the system's behavior. We propose exploiting three sources of measurements. First, during development, autonomic managers can take advantage of existing testing procedures to characterize the evolution of the system over time. Moreover, as discussed in Chapter~\ref{chapter:architectural-framework}, testing procedures can be used to evaluate the system's response to changes in its configuration. Second, autonomic managers can use historical data to evaluate what-if scenarios. Action plans can be tried out as simulations prior to materializing them into the managed system. In this case, past measurements embody the current system's behavior under specific operation conditions. This is useful to contrast results from hypothetical scenarios. And third, run-time monitoring provides unique insights into actual usage patterns, system performance, management cost, among many others. This information is key to measure the impact of changes on the development and planning side. 

	\item[Recall and Synthesis\autodot] Recall refers to a system's ability to obtain relevant information from the knowledge layer. Ideally, autonomic managers can focus their attention on the particular subset of the knowledge that will increase prediction accuracy. The synthesis process refers to autonomic managers' ability to reify and optimize knowledge artifacts, and make them available to other managing systems, as well as offline stakeholders.
\end{description}

\subsubsection{Online Knowledge Synthesis}
\label{subsect:reference-architecture--online-knowledge-synthesis}

As demonstrated in Chapter~\ref{chapter:delivery-platform}, run-time monitoring is a key enabler for realizing the continuous evolution cycle. Monitoring information is consolidated into data repositories and run-time models that reflect an up-to-date snapshot of the system's behavior and structure. High levels of representation fidelity enable accurate predictions, further analysis and improvement of the system. Nevertheless, the evolution operational mode poses knowledge requirements beyond collecting data.

Data collection is a common industry practice that leads to a better understanding of usage patterns and emerging behaviors. This is even more prevalent in \gls{iot} and \gls{cps}, where connected devices, such as buses and traffic sensors, are constantly sending measurements to data warehouses or data lakes (\cf{Measurement in Figure~\ref{fig:reference-architecture--implicit-and-explicit-knowledge-processing}}). We posit that this is passive knowledge: data collections waiting to be processed by human operators through data mining or machine learning techniques. In contrast, we define active knowledge as any type of artifact that captures domain- and system-specific patterns, insights and dynamics from data. They can be exploited by managing systems to predict future states, support run-time decision making, and populate the evolution (and adaptation) space.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.95\columnwidth]{fig/reference-architecture/reference-architecture--engineering-cycle.pdf}
	\caption{Conceptual continuous engineering cycle for run-time evolution}
	\label{fig:reference-architecture--continuous-engineering-cycle}
\end{figure}

The concepts of active knowledge and evolution cycle converge into our envisioned continuous engineering cycle, depicted in Figure~\ref{fig:reference-architecture--continuous-engineering-cycle}. This cycle comprises three main concepts: passive knowledge (\cf{$\encirclepurple{1}$}), evolution space (\cf{$\encirclepurple{2}$}), and active knowledge (\cf{$\encirclepurple{3}$}). We argue that there is a natural transition from collecting and storing data (\ie{passive knowledge} gathered from the managed system) to populate and explore future configuration states (\ie{evolution space}), ultimately to synthesize executable models (\ie{active knowledge}). In terms of control, these transitions can be seen as the dynamics between evolution, adaptation and operation. Changes in the evolution space affect the possible adaptation scenarios, thus determining the actual operational states. As shown in Figure~\ref{fig:reference-architecture--continuous-engineering-cycle}, key techniques for realizing our continuous engineering cycle are evolutionary algorithms, online experimentation, model approximation, estimation or inference methods, as well as optimization methods (\eg{hyperparameter optimization}).

There are two ways of synthesizing active knowledge. On the one hand, based on data collected from deployed sensors, managing systems can fit statistical models to describe the current service demand (\eg{passenger arrivals at each bus station}), the current bus frequency per line and station, and other behaviors related to the system's operation. This process is represented by the arrow connecting labels~$\encirclepurple{1}$ and~$\encirclepurple{3}$ in Figure~\ref{fig:reference-architecture--continuous-engineering-cycle}. On the other hand, synthesizing predictive models based on collected data may be too limiting in terms of the capacity to accommodate uncertainty. Since the models would be synthesized based on known execution conditions, their usefulness in handling unknown situations is very limited. Therefore, an intermediate exploration step is required to augment the data. Its objective is to generate enough information about the search space to be able to capture the dynamics between configuration parameters and the metrics. By exploring the search space of potential configuration alternatives, managing systems can reify knowledge artifacts that enable managed systems to respond to emerging situations, even if they have not occurred before. This process is represented by label~$\encirclepurple{2}$ in Figure~\ref{fig:reference-architecture--continuous-engineering-cycle}. The full cycle, represented by labels ~$\encirclepurple{1}$--$\encirclepurple{3}$, realizes \gls{miac} through model identification (\ie{model estimation}). As shown in Figure~\ref{fig:reference-architecture--continuous-engineering-cycle}, estimated models are then used as control inputs to adapt the managed system.

The purpose of exploring the search space is twofold. First, collected data can be augmented as previously explained. Second, managing systems can try out distinct configurations of the managed system, as explained in Chapter~\ref{chapter:architectural-framework}, to find possible solutions to an ongoing situation. As an example, consider our \gls{suts} case study. In the event that a street becomes inaccessible, the managing system may run scenarios to determine a routing plan quickly, and continue the operation while minimizing the impact. In any case, a genetic algorithm is used to generate chromosomes (\ie{configurations}) and evaluate their fitness based on metrics of interest, such as the excess waiting time and the headway coefficient of variation in our \gls{suts} case study. Since field experiments would be too expensive, time demanding, or simply damaging to the system's operation, the experiments are conducted in a controlled environment. For example, the experimentation system can derive simulation models based on the chromosomes.

\begin{figure}[h]
	\centering
	\includegraphics[width=1\columnwidth]{fig/reference-architecture/reference-architecture--predictive-knowledge-synthesis.pdf}
	\caption{Iterative process to optimize configuration parameters}
	\label{fig:reference-architecture--knowledge-reification}
\end{figure}

Figure~\ref{fig:reference-architecture--knowledge-reification} illustrates an iterative process combining the techniques mentioned above: function reification, experimentation and evolutionary optimization. The main purpose of this process is to devise optimized operation parameters, as explained in Section~\ref{subsubsect:reference-architecture--goal-achievement-through-optimization}. Figure~\ref{fig:reference-architecture--knowledge-reification} combines knowledge outcomes produced by the \gls{mim} and \gls{am} components. There are three sources of information feeding the reification process. The first two sources are non-functional testing and monitoring, which create metrics measurements at test-time and run-time, respectively (\cf{Figure~\ref{fig:reference-architecture--implicit-and-explicit-knowledge-processing}}). The third source of information is the evaluation of configuration scenarios. This process is triggered by either the \gls{mim} or the \gls{am} at run-time, if the estimated error is unacceptable, or from another autonomic manager running in a non-production environment (\eg{the self-improvement feedback loop presented in Chapter~\ref{chapter:architectural-framework}}). In either case, a combined data set is passed to the experimentation subsystem. Once the functions are reified, and the estimated error is good enough, each parameter is optimized based on the corresponding viability zones.


\section{Chapter Summary}
\label{sect:reference-architecture--summary}

The proliferation of Smart Cyber-Physical Systems (\gls{scps}) and technological advances in Artificial Intelligence, Big Data, Cloud Computing and the Internet of Things are increasingly blending physical entities with their digital counterparts. This blending, however, challenges researchers to design reliable and dependable self-management capabilities, able of adapting and evolving autonomously to deal with unanticipated and emerging behavior at run-time.

This chapter presented our run-time evolution reference architecture for guiding the design of dependable and resilient \gls{cps}. Our architecture constitutes a blueprint for architecting \gls{scps} where self-evolution and self-adaptation work in harmony to achieve the system's operational goals autonomously. Self-adaptation and self-evolution constitute two operational modes of an autonomic manager for realizing a continuous evolution loop. In the forward direction, managing systems keep internal models and other forms of knowledge in sync with the natural evolution of the \gls{cps}. In the reverse direction, managing systems deliver short-term and long-term updates, such as operational corrections and optimizations. Thereby, our architecture addresses the dependability of run-time decisions, as well as the overall resiliency of the operation.

Increased autonomy in complex \gls{cps} raises various research challenges regarding the dependability and resiliency of \gls{cps}. On the one hand, \gls{cps} designers ought to introduce mechanisms to guarantee predicted outcomes of the adaptations and evolution actions planned and conducted at run-time. Failing to do so may cause a faulty behavior, increased operational costs or even safety issues. Our reference architecture addresses this challenge by accounting for the design and execution of online experiments. Experimentation plays a two-fold role in our architecture: exploration of the evolution and adaptation space, as well as run-time assurance. More specifically, the factors contributing to dependability are: Error mitigation through multi-model identification; Reliable models through model inference; Evidence collection through experimentation; And autonomic behavior through adaptive control. On the other hand, \gls{cps} must exhibit, and work under, resilient operation even in the presence of uncertainty. Our reference architecture extends the notion of a viability zone and includes it as a supervisor component. Whenever a variable of interest starts behaving in an unexpected way, the supervisor component will switch between the adaptation and the evolution operational modes as needed. Moreover, the major components realizing these two modes of operation will ensure that the controller has the most appropriate parameters to plan corrective actions. The factors contributing to resiliency are: Predictable adaptation through reliable models; Run-time validation through evidence collection; Error mitigation through parameter estimation; Goal achievement through hyperparameter optimization; And Assurance at run-time through viability zones and control objectives.

The proposed reference architecture comprises two main components. On the one hand, a model identification mechanism (\gls{mim}) approximates \glspl{mart} to describe system metrics, such as the excess waiting time. These models serve as a reference input to guide the adaptation and operation of the managed system. The \gls{mim} uses various types of execution environments to simulate the managed system under specific context conditions, thus generating key performance indicators, such as the excess waiting time and the headway coefficient of variation. A genetic algorithm guides the evolution space exploration, running the simulated system as part of the fitness value calculation. Online experimentation is a key technique to optimize the exploration process as well as clustering results based on similarity. Moreover, we detail the process for synthesizing insights at run-time through active and passive (\ie{declarative}) knowledge, a base requirement for value aggregation. Furthermore, the \gls{mim} exemplifies the kind of updates autonomic managers can deliver as part of the evolution cycle. On the other hand, an execution adjustment mechanism (\gls{am}) finds appropriate control parameters so that the controller can enforce the control objectives in the \gls{cps}. The \gls{am} constitutes an example of how to exploit active knowledge to realize self-adaptation. It uses reified functions to optimize the control parameters with respect to a given setpoint (\ie{the associated control objective}). Moreover, this component exemplifies a way to associate the evolution, adaptation and operational spaces. In this case, the approximated function, constrained by the setpoint, determines the possible configuration parameters that guide the adaptation and eventually the operation.

This chapter concludes our focus on self-evolution through self-management, self-improvement, and self-regulation. Next chapter presents the evaluation of our contributions based on the two case studies introduced in Chapter~\ref{chapter:contribution-overview}, namely cloud infrastructure management and smart urban transportation.
