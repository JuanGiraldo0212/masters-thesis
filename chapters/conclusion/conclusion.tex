\startchapter{Conclusions}
\label{chapter:conclusions}

\minitoc

In this chapter, we present a dissertation summary by revisiting the research challenges and goals we addressed, as well as the corresponding contributions. In light of the latter, this chapter concludes this dissertation with a discussion of future research opportunities.

\section{Dissertation Summary}
\label{sect:conclusions--dissertation-summary}

In this dissertation, we have addressed and solved several challenges regarding the problem of self-evolution. The fundamental motivation behind our research concerns the extension of autonomic computing from execution to development. We focused on two key aspects of this task. On the one hand, we explored the notion of self-improvement on the development side. We addressed the implicit traditional assumption, in both software engineering and autonomic computing, that, apart from stakeholdersâ€™ work, nothing else can be done to modify the software while it is being developed. In other words, software changes originate with stakeholders. On the other hand, we identified and addressed software evolution concerns stemming from the automation of development aspects, such as the validity, quality and effectiveness of changes enacted online.

The research problem addressed in this dissertation was to contribute to the incremental improvement of software design, configuration and deployment continuously and autonomously. Our solution strategy is fourfold. First, we devised a framework to integrate development-time and run-time autonomic work based on software changes and knowledge. Second, we developed a feedback loop to monitor and identify run-time variability, and realize corresponding software changes to configuration source code. Third, we developed an experimentation-driven feedback loop to explore, discover and realize software design and configuration alternatives, aiming to improve \glspl{kpi}. Finally, we designed a reference architecture for run-time software evolution with two alternating operational modes, namely self-adaptation and self-evolution. Its main goal is to keep knowledge artifacts relevant in the face of emerging behavior, aiming to reduce maintenance work.

\subsection{Addressed Challenges and Goals}
\label{subsect:conclusions--challenges-and-goals}

We constrained the research problem by stating a set of research challenges, which we classified into two groups: \emph{self-evolution} and \emph{self-improvement}. In the following, we summarized how we solved the addressed challenges stated for this dissertation.

\textit{Self-evolution}

\begin{description}[leftmargin=4.2em]
	\item[\textsc{Ch}1:] \emph{Self-evolution mechanisms should be compatible with practices of continuous software engineering for quality assurance}. We developed a software evolution pipeline based on the practices of \gls{cd} (\ie{the delivery pipeline}) and \gls{ci}. Our pipeline allows autonomic managers to realize code updates through run-time domain-specific model modifications. Therefore, autonomic managers exploit existing infrastructure for software testing and quality checking, through the use of repository management and contribution models provided by our evolution pipeline.

	\item[\textsc{Ch}2:] \emph{Autonomic managers should provide the criteria and decision-making process behind a change}. The implementation strategy of our self-improvement feedback loop is based on experimentation and evolutionary optimization. Therefore, autonomic managers can present stakeholders with descriptive statistics of the executed experiment trials, in terms of the subject \glspl{kpi}, and pair-wise trial comparisons in the form of raw data and charts. This information constitutes statistical evidence that explains the decisions behind a proposed improvement.

	\item[\textsc{Ch}3:] \emph{Self-evolution mechanisms should capture live infrastructure modifications and propose corresponding software changes}. Our \textsc{Fork and Collect} provides a simplified view of the computing infrastructure that a run-time agent uses to trigger a transformation chain. As a result, the agent captures the infrastructure's current state as a \gls{mart}. Our pipeline's evolution coordinator compares the current and new \glspl{mart}, and triggers a source code update, as well as an \gls{iac} template instance update, when changes are detected.
\end{description}

\textit{Self-improvement}

\begin{description}[leftmargin=4.2em]
	\item[\textsc{Ch}4:] \emph{Self-improvement mechanisms should use design and analysis of experiments to explore system alternatives for the dimensions of interest}. Our feedback loop for self-improvement separates concerns by dedicating one feedback loop to manage high-level experimentation goals (\ie{The \gls{efl}}), and two others for configuration and architecture variants (\ie{The \gls{pfl} and \gls{cfl}, respectively}). The \gls{efl} directs the search space exploration based on pair-wise trial comparisons and a specific \gls{kpi} goal.

	\item[\textsc{Ch}5:] \emph{Self-improvement mechanisms should factor execution conditions into the experiment design}. Our self-improvement feedback loop reuses load testing procedures already present in the source repository. By doing this, it ensures that system variants are tested following appropriate quality concerns. That is, variants are assessed based on what the software development team considers relevant.

	\item[\textsc{Ch}6:] \emph{Autonomic managers are required to keep their internal models relevant, aiming to reduce the need for additional maintenance}. Our reference architecture for run-time evolution is based on \gls{mrac} and \gls{miac}. The former allows adapting adaptation mechanisms to new reference models. The latter allows identifying, reifying and updating the reference models. Our architecture alternates between these two components, going from short-term adaptations to long-term evolution actions according to changes in the system's environment.
\end{description}

In light of these challenges, we pursued the general goal of creating an autonomic and continuous software evolution process. We reconceptualized and repurposed methods of autonomic computing in light of advances in continuous software engineering. More specifically, we developed self-evolution mechanisms through self-improvement, self-regulation and self-management, and integrated them into the software delivery pipeline. We refined this goal by adopting four specific goals, as follows:

\begin{description}[leftmargin=3.5em]
	\item[G1:] We established a general solution strategy for integrating offline and online software changes and knowledge. 
	\item[G2:] We developed a software evolution pipeline to capture run-time changes in the computing infrastructure and realize corresponding software changes on the development side.
	\item[G3:] We developed self-improvement driven by experimentation and evolutionary optimization to devise, execute, and monitor architecture and infrastructure variants, aiming to improve \glspl{kpi} autonomously and continuously.
	\item[G4:] We designed a reference architecture for run-time software evolution to evolve the reference models guiding adaptations to the managed system.
\end{description}

In the following section, we discuss our achieved contributions with respect to these goals and challenges.

\subsection{Contributions}
\label{subsect:conclusions--contributions}

We presented our contributions according to their role in our offline and online reconceptualization. First, our continuous software evolution pipeline bridges run-time changes with corresponding updates on the development side. That is, it connects the production and integration environments from the software delivery pipeline. Second, our quality-driven self-improvement feedback loop explores configuration alternatives to improve \glspl{kpi}. It does so on the development environment. Finally, our run-time evolution reference architecture guides the design of dependable autonomic behavior and resilient operation. It focuses on run-time aspects of managed systems, thereby occupying the production environment. We summarize these contributions, as follows:

\begin{description}[style=unboxed,leftmargin=0cm,font=\bfseries\normalsize]
	\item[\textsc{C}1: Continuous Software Evolution Pipeline\autodot]

	% Establish a general solution to integrate development-time and run-time autonomic work
	To address goal \textsc{G}1, we proposed a continuous software evolution pipeline to bridge offline and online evolution processes. We took advantage of existing infrastructure and automation intended for software delivery, and put it into service of autonomic managers. Our pipeline extends the concept of \gls{ci} to complete the evolution loop in DevOps  (\ie{Dev$\,\leftarrow\,$Ops}). That is, software changes stem not only from offline processes---driven by stakeholders, but also from online activities---driven by autonomic managers. Therefore, our pipeline enables feedback loops to produce online changes through \glspl{mart}, focusing on domain-specific modifications rather than low-level code updates. The integration of these updates into source specifications follows standard practices of software engineering, including repository management, branching and contribution models, among others. This means that online modifications to source code go through existing testing procedures to guarantee minimum and acceptable levels of quality. Conceptually, our evolution pipeline extends \gls{ci}, thus realizing two-way \gls{ci}. Thereby, our software evolution pipeline realizes a holistic and continuous process that connects software execution and development, while providing quality control to online changes.

	% Develop a self-evolution mechanism to update development and knowledge artifacts whenever the execution environment changes
	To address goal \textsc{G}2, we devised a round-trip engineering strategy to reconcile the evolution of run-time and development-time artifacts. From left to right (\ie{forward engineering}), we rely on the delivery pipeline as it is, considering only a few alterations. From right to left (\ie{reverse engineering}), we put in place a model-driven system to monitor and transform run-time changes into various types of persistent updates. Our reverse engineering strategy comprises two main components: run-time state synchronization and automatic source specification update. We separate these workflows based on their primary concern: \gls{mart} evolution and specification update. The former is based on our \textsc{Fork and Collect} algorithm for \gls{api} monitoring and \gls{mart} evolution, while the latter is based on textual and structural model transformations.

	To evaluate this contribution, we conducted two application scenarios focused on functional validation. Our validation walks through, step by step, how our prototypes work. The first scenario addressed the creation of an \gls{iac} template and its corresponding instance from resources deployed to a target cloud environment. This scenario validated the feasibility of our model transformation chain, our algorithm for run-time cloud monitoring and \gls{mart} evolution, and the integration of software tools from the \gls{iac} life cycle. The second scenario addressed how the pipeline handles changes on either side of the integration loop to prevent configuration drift. We evaluated the effectiveness of the direct and \gls{ci}-aware evolution workflows, which determine whether run-time changes are integrated following standard practices of quality checking or bypasses them. These application scenarios demonstrate how our software evolution pipeline integrates online changes into the software evolution process on the development side. Thereby, our pipeline directly contributes to eliminating a remaining discontinuity from the software development process, namely continuous evolution of development artifacts (\cf{Section~\ref{sect:overview--off-line-and-on-line-reconceptualization}}). Furthermore, by connecting the offline and online sides of the software evolution process, we prevent the emergence of technical debt in \gls{iac} stemming from run-time variability. This is a significant step toward explicitly connecting other software engineering processes. Thus, we lay a foundation for the exploitation of autonomic managers throughout the delivery pipeline.

	\item[\textsc{C}2: Quality-driven Self-Improvement Feedback Loop\autodot]

	% Develop an experimentation-driven self-improvement mechanism to improve key performance indicators during development
	To address goal \textsc{G}3, we proposed a feedback loop for exploring design and configuration alternatives during development. The main purpose of this feedback loop is to improve \glspl{kpi} continuously while the system is running on the development environment. We connected our feedback loop with our continuous software evolution pipeline through two modeling layers, namely: the virtual computing infrastructure and the software architecture. This means that our feedback loop focuses on exploring configuration variants and finding possible improvements. Corresponding source specification updates are delegated to our software evolution pipeline. The feedback loop stops and triggers the source specification update when it identifies a variant that outperforms the baseline configuration (\ie{the system as it runs on production}).

	Our feedback loop relies on existing quality assessment and testing procedures present in the delivery pipeline. By extending quality assessment with continuous improvement, our feedback loop frees stakeholders from maintenance work and expedites the implementation of incremental software changes. We followed the separation of concerns principle by splitting the online experiment management into three internal feedback loops. The first one addresses the satisfaction of high-level goals through online experiment design. The second one focuses on the derivation, deployment and monitoring of infrastructure configuration variants. Finally, the third one focuses on the derivation, deployment and monitoring of architectural design variants. Both the second and third feedback loops apply combinatorial techniques to derive variants. In the first case, the feedback loop varies configuration parameters of declared virtual resources. In the second case, the feedback loop explores the application of domain-specific design patterns throughout the software architecture.

	To evaluate this contribution, we conducted an application scenario focused on experimental validation. The scenario addresses our prototype implementation of the feedback loop for exploring software architecture variants. We provide a simple software architecture to the feedback loop composed of an \gls{api} component and an \acrshort{grpc} worker. The feedback loop generates hundreds of variants by combining these components with domain-specific design patterns for distributed processing and cloud computing. However, because some of the design patterns we implemented contain application-specific components, this step is semi-automated. Therefore, the experiment ended up containing six architecture variants. Each of them was tested under three execution scenarios, namely constant traffic, linear traffic growth, and traffic spike. These scenarios were used to explore the search space, collecting valuable data to compare the variants in terms of service latency. The results of our proof of concept evaluation provided evidence supporting our long-term vision. On the one hand, variations of a software architecture can be better equipped to cope with distinct execution scenarios. On the other hand, our self-improvement feedback loop found an appropriate architecture variant that improves the baseline architecture. This means that it can indeed contribute to the long term evolution of the subject software system. Since the feedback loop is a part of the delivery pipeline, improvements are discovered and applied continuously. Thereby, our feedback loop contributes to eliminate a remaining discontinuity from the software development process, namely continuous adjustment of design, configuration and deployment. Moreover, our solution strategy allows exploiting the outcome of the search space exploration in other environments, where it can complement knowledge managed by other autonomic managers. This, in combination with our software evolution pipeline, constitute cooperative self-evolution, a process analogous to how stakeholders contribute to develop software.
	
%	\begin{description}[leftmargin=0pt,font=\normalfont\itshape]
%		\item[First scenario:] We provide a simple software architecture to the feedback loop composed of an \gls{api} component and an \acrshort{grpc} worker. The feedback loop generates hundreds of variants by combining these components with domain-specific design patterns for distributed processing and cloud computing. However, because some of the design patterns we implemented contain application-specific components, this step is semi-automated. Therefore, the experiment ended up containing six architecture variants. Each of them was tested under three execution scenarios, namely constant traffic, linear traffic growth, and traffic spike. These scenarios were used to explore the search space, collecting valuable data to compare the variants in terms of service latency.
%		
%		\item[Second scenario:] Similarly to the first scenario, we provide a base implementation for the subject system's computing cluster. Each infrastructure variant deployed the same application as in the first scenario, and tested them under the constant traffic scenario. Our results demonstrated that given an architecture variant, our feedback loop can find an appropriate cluster configuration, minimizing the application's service latency.
%	\end{description}
%	
%	The results of our proof of concept evaluation provided evidence supporting our long-term vision. On the one hand, variations of a software architecture can be better equipped to cope with distinct execution scenarios. On the other hand, our self-improvement feedback loop found an appropriate architecture variant that improves the baseline variant. This means that it can indeed contribute to the long term evolution of the subject software system. Since the feedback loop is a part of the delivery pipeline, improvements are discovered and applied continuously. Thereby, our feedback loop contributes to eliminate a remaining discontinuity from the software development process, namely continuous adjustment of design, configuration and deployment.

	\item[\textsc{C}3: Run-Time Evolution Reference Architecture\autodot]

	% Define required design elements to keep adaptation mechanisms relevant when facing emerging behavior
	To address goal \textsc{G}4, we proposed a reference architecture for keeping adaptation decisions relevant in the face of emerging behavior. Our architecture considers temporary as well as long-lasting control actions as a way to countermeasure the evolution of the operation environment over time. In light of this, we chose as architectural drivers the dependability of autonomic decisions, and the resiliency of the managed system's operation. In the first case, we proposed software components based on \gls{miac}, thus making model estimation the cornerstone of our long-term evolution approach. Moreover, we envisioned multiple strategies to contribute to dependability, namely: error mitigation through multi-model identification, reliable models through model inference, evidence collection through experimentation, and autonomic behavior through adaptive control. In the second case, we proposed software components based on \gls{mrac}, thus relying on self-adaptation to correct minor and temporary deviations from expected system behavior. The strategies we envisioned to contribute to operation resiliency are: predictable adaptation through reliable models, run-time validation through evidence collection, error mitigation through parameter estimation, goal achievement through hyperparameter optimization, and assurance at run-time through viability zones and control objectives.

	The proposed architecture realizes a continuous engineering cycle where adaptation and evolution work cooperatively to achieve the system goals. The main purpose of our engineering cycle is to regulate the reference models used for controlling the system's operation, thus, ultimately contributing to the managed system's long-term evolution. We achieved the envisioned engineering cycle as follows. First, our architecture uses evolutionary optimization and online experimentation to find suitable control reference models. Second, it uses online experimentation, supported by parameter optimization, to gather evidence of statistically significant improvements over the running system, thus generating knowledge of possible configuration states and their respective performances. Lastly, our reference architecture accommodates self-evolution for reflecting persistent changes in the operation environment as well as improving the use of resources. The proposed architecture uses self-adaptation to ensure that the managed system operates within acceptable and viable boundaries. Together, these characteristics contribute to achieving the architectural drivers.

	To evaluate this contribution, we used the proposed models and followed the architecture's guidelines for modeling and implementing prototypes of the main components for our \gls{suts} case study, namely \gls{mim} and \gls{am}. We conducted an application scenario focused on functional validation. It evaluated our prototype's ability to identify a predictive function for optimizing the excess waiting time, a metric of user experience. Our results show that the \gls{mim} was able to approximate a function to describe the user experience metric using two estimators, based on cubic interpolation and symbolic regression. Therefore, this component is capable of synthesizing active and passive knowledge in the form of data and functions. This is a significant step toward synthesizing and evaluating possible adaptation scenarios before manifesting them in the actual system. Moreover, we showed how our proof of concept transitions from evolution to adaptation using our second prototype, the \gls{am}. With this, we show the consistency and feasibility of our reference architecture for guiding software architects on how to apply it for engineering \gls{scps}.
\end{description}


\subsection{Contributions Significance}
\label{subsect:conclusions--significance}

% A separator
%\begin{center}
%	$\ast$~$\ast$~$\ast$
%\end{center}

In recent years, the software industry has been focused on shortening the feedback cycle from post-deployment activities back to development. Great advances in configuration and deployment technology have increased the pace at which software development teams deliver value added services. The success of these efforts has caused the emergence of new challenges that stress the abilities of highly skilled IT personnel to develop and fix mission-critical functionality, maintain existing software and infrastructure implementations, detect and remove technical debt, migrate existing software to modern technologies, refactor design choices, among many others. Various factors call for a radical change to how software is developed and maintained, including increasingly complex software development and operation environments, the anticipated massive increase of interconnected devices~\cite{alsen-2017-future,dahlqvist-2019-growing}, and the dependability and resiliency expectations that come with hyper-connectivity. 

Future software engineering practices must break out from forward-only life cycle models (\ie{development~$\rightarrow$~execution}), legacy of waterfall development. Instead, a bidirectional model is necessary, where changes are planned, designed, developed and deployed in both directions (\ie{offline~$\rightleftarrows$~online}) continuously and relying on manual and automated practices on both sides. Such a process will unlock software's potential to an extent unattainable for the prevalent focus of the software industry---a need for speed through shorter software release cycles~\cite{fitzgerald-2017-continuous}. In this context, new methodologies, infrastructures and tools are required to realize software evolution online, and fully connect it to its offline counterpart. In this sense, the contributions we present in this dissertation lay down the foundation to establish new foci for software engineering and autonomic computing. We have contributed concrete approaches to realize the required platform to integrate the automated and manual sides of our envisioned software evolution process. We believe that our approaches bring short-term benefits to software development teams. However, we anticipate that our contribution to the state of the art will stimulate further progress in the long term. New products ought to be developed to strengthen information access from every computing environment going from development to production, but especially from production back to planning, design, and development. Such an access to information will boost a new era of automated tools, thus pushing toward the standardization of online processes,\footnote{Possibly following and refining ISO/IEC/IEEE 12207---\emph{Systems and software engineering -- Software life cycle processes}} and the emergence of libraries, frameworks and services for self-evolution with increased autonomy.

\section{Future Work}
\label{sect:conclusions--future-work}

This dissertation concludes with a presentation of selected future work opportunities emerging from our research.

\subsection{Long-Term Software Evolution}
\label{subsect:conclusions--fw-long-term-software-evolution}

Our run-time evolution reference architecture concentrates on improving \glspl{cps} dependability and resiliency through self-evolution and self-adaptation. They are based on the managing system's capability to represent entities in the managed system's environment accurately. Furthermore, these representations must be kept always up to date and in sync with the entities they model. Since our reference architecture focuses on \glspl{mart}, various design concerns remain open research challenges. As elaborated in Section~\ref{subsect:reference-architecture--adaptation-and-evolution-as-operational-modes}, the regulation relationship we propose differs from the control relationship between managed and managing systems. Since the autonomic systems we propose are not regular autonomic managers or controllers, the interface between them and \glspl{cps} is of a different nature. The value delivered goes beyond execution control (\ie{sensing and effecting change}). A first open challenge is to define concrete design elements that provide the autonomic system with appropriate interfaces to interact with its \gls{cps} in the opportune moments. These elements comprise, for example, the life cycle of persistent evolution actions that may affect physical entities or the policies that govern them (\eg{the \gls{osp}}). Another design challenge concerns identifying the structures to represent past, present and future states and their interrelationships. A concrete representation of these states would enable the autonomic system to reason about the evolution and adaptation spaces with respect to current viability zones. This type of meta-analysis allows finding unexplored alternatives in a proactive way, thus potentially speeding up the evolution process when it is actually needed. Finally, a third challenge refers to exploring the proactive role of long-term evolution. In the context of our \gls{suts} case study, an autonomic system can investigate the best way of distributing the various types of vehicles based on current passenger demand per line and stop. It can study the placement of new stops, or even propose the need for studying them. This proactive role is contrary to the reactive approach we explored in Chapter~\ref{chapter:reference-architecture} (\ie{as a countermeasure to emerging behavior}), and is worth exploring independently.

A second group of challenges concerns the control dynamics between run-time self-evolution and self-adaptation. Our architecture establishes a control hierarchy in which the evolution process affects the possible adaptations, and these in turn affect the potential operational states. That is, the evolution space dictates which configurations in the adaptation space are possible, eventually reducing the operational space to a set of concrete instances. A first challenge refers to taking advantage of new adaptation opportunities opened up by a newly explored evolution scenario. For example, imagine that an autonomic manager transforms a software system's architecture from a simple client-server structure to a load-balanced service. The adaptation mechanism can take advantage of the hardware properties as before, but also of the number of service instances and the load balancing algorithm. The adaptation space not only grew in possible adaptations, but is now considering new parameters, thus affecting previous metric calculations. A second challenge consists in predicting the effect that the new parameters have over previous adaptation scenarios, at least while new experiments are conducted. Lastly, as new sensors are deployed and new metrics appear, a third open challenge concerns the reasoning capabilities of the evolution process to increase the accuracy of existing reference models when new data become available. Doing so would decrease the likelihood of unintended effects after system adaptations.

Finally, future advances in dependable autonomy for \glspl{cps} to improve system resiliency should address safety and security concerns. Although these properties were out of the scope of this dissertation, they are fundamental to guarantee the stability of the system and trustworthiness of adaptations and evolution actions at run-time.

\subsection{Knowledge-Preserving Experimentation}
\label{subsect:conclusions--fw-knowledge-perserving-experimentation}

The combinatorial explosion of configuration options may produce large search spaces. Since evaluating configuration alternatives requires deploying software to a controlled environment, conducting experiments will likely require much time and computing resources. Moreover, since experiments are being conducted continuously, they may be too expensive, which would increase the total cost of ownership. This situation would defeat the purpose of anticipating adverse conditions or proactively exploring improvements during development. Therefore, self-improvement mechanisms should minimize experimentation time by using resources efficiently. More importantly, they should take advantage of past results to avoid running unnecessary trials. However, even considering these measures, the research challenge may remain open. In addition to reusing past results from whole trials, feedback loops should preserve partial knowledge across trials. That is, granular results from past executions (\eg{knowledge at the gene level when working with chromosomes}) to exclude, or include, trials based on a predicted performance. For example, if a gene is known for causing long latency times, chromosomes including the gene can be excluded to prevent under-performing trials.

Failing to address the aforementioned challenge may prevent the adoption of this technology, especially in the context of the delivery pipeline. Imagine, for example, that successive releases to the development environment cause an exhaustive search exploration every time. In contrast, an experimentation mechanism that optimizes its use of resources would only run a few trials to study \glspl{kpi} of newly added parts. In this sense, experimentation can be paired with \gls{ai} models, thus realizing an incremental learning strategy.

%\subsection{Operational Design Patterns}
%\label{subsect:conclusions--operational-design-patterns}
%
%% TODO

\subsection{Software Engineering at Run-Time}
\label{subsect:conclusions--software-engineering-at-run-time}

In 2001, autonomic computing was deemed as the only alternative to a looming software complexity crisis. It was born to reduce human intervention in the everyday management of computing systems. It was then, and has been, a complement to the work produced by software development teams. In contrast, two decades later, the complexity problem has extended to the left, challenging now the software industry to keep up with the pace of change on the development side.

We draw a parallel between the early days of software engineering and what is emerging now. The so-called software crisis of the 1960s, 1970s and 1980s spurred the early beginning of software engineering. Cost and budget overruns and critical quality issues motivated the later standardization of the discipline into software development processes, methodologies and life cycle models. We believe that the current growth rate of software systems, the increasing complexity of operation environments, and the shortage of technical personnel are significant factors pushing for a similar shift. The advent of \gls{ai} technology in software development has already started attracting early adopters, especially in open source projects where licensing issues are less restrictive.\footnote{Since \gls{ai} models are being trained on public data sets and code licensed under open source licenses, recommendations and contributions made by \gls{ai} tools cannot be applied on proprietary source code.} It's only a matter of time until \gls{ai}-based tools penetrate the software industry for performing development tasks that are currently being conducted by human stakeholders. We foresee a new era of standardization for software engineering. Our contributions in this dissertation point in this direction. However, in this scenario, autonomic computing represents the early beginning of such a new era. One where processes and life cycle models are digital and programmable. We call this new era \emph{software engineering at run-time}.

%Although our vision is yet to be accepted by the research community, we can already identify points of convergence. Various communities have emerged with the common theme of @run.time---or \emph{at run-time}. Examples of these are requirements engineering, validation and verification, and quality assurance. Moreover, architectures and reference models for autonomic computing tend to revolve around the same online activities, namely: monitoring, goal management, analysis, change management, and evolution. These activities are, in fact, aligned with processes from ISO/IEC/IEEE 12207---\emph{Systems and software engineering -- Software life cycle processes}. They resemble concerns from Measurement, Knowledge Management, Decision Management, Risk Management, Quality Assurance, and Configuration Management.

% TODO Add a closing statement to the last paragraph

% Standardize online processes - Give more freedom to autonomic systems for devising adaptation strategies at run-time
% Integrate offline and online processes, thus creating an autonomic software development life cycle model?
